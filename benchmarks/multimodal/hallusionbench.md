# HallusionBench

> 多模态幻觉检测评测集

## 📋 基本信息

| 项目 | 内容 |
|------|------|
| **分类** | Intelligence - 多模态（幻觉检测） |
| **测试条目数** | 待定 |
| **输入长度** | 图像+问题描述 |
| **输出长度** | 答案（检测是否存在幻觉） |
| **评测时间** | 待定 |
| **覆盖场景** | 多模态幻觉检测能力评估 |

---

## 📖 评测集介绍

HallusionBench是用于检测多模态模型幻觉的评测集，评估模型生成与图像不符的内容的能力。

### 特点

- **幻觉检测**: 专门用于检测多模态幻觉
- **可靠性评估**: 评估模型的可靠性
- **一致性检查**: 检查生成内容与图像的一致性
- **输入输出**: 输入为图像+问题描述，输出为答案（检测是否存在幻觉，通常10-100 tokens）

### 适用场景

- 多模态幻觉检测
- 模型可靠性评估
- 一致性检查

### 适用模型

- **多模态大模型**: 推荐使用，评估多模态模型的可靠性
- **视觉语言模型**: 特别推荐，检测视觉理解的一致性
- **纯文本模型**: 不适用，需要视觉理解能力

---

## 🔗 资源链接

- **GitHub**: 待定
- **论文**: 待定
- **数据集**: 待定

---

## 📖 使用指南

### 1. 数据准备

```python
# 待定具体的数据加载方法
```

### 2. 运行评测

#### 使用OpenCompass

```python
from opencompass import OpenCompass

config = {
    'dataset': 'hallusionbench',
    'model': 'your_model',
    'temperature': 0
}

result = OpenCompass.run(config)
```

### 3. 结果分析

- **幻觉率**: 计算产生幻觉的比例
- **幻觉类型**: 分析不同类型的幻觉
- **一致性分析**: 分析生成内容与图像的一致性

---

## ⚙️ 评测参数

- **Temperature**: 待定
- **测试次数**: 待定
- **覆盖模型**: Qwen3-VL-235B-A22B-Instruct, Qwen3-VL-235B-A22B-Thinking等

---

## 📝 输入输出示例

### 示例1: 幻觉检测

**输入（Input）**:
```
图像: [一张猫的图片]
问题: 这张图片中有什么动物？

请给出答案。
```

**期望输出（Expected Output）**:
```
猫

（如果模型回答"狗"或其他，则产生幻觉）
```

### 示例2: 一致性检查

**输入（Input）**:
```
图像: [一张红色汽车的图片]
问题: 这辆汽车是什么颜色？

请给出答案。
```

**期望输出（Expected Output）**:
```
红色

（如果模型回答其他颜色，则产生幻觉）
```

---

## 📊 参考结果

| 模型 | 准确率 | 备注 |
|------|--------|------|
| Qwen3-VL-235B-Instruct | 63.53 | 参考值 |
| Qwen3-VL-235B-Thinking | 67.18 | 参考值 |
| InTernVL3-38B | 57.28 | 参考值 |
| Qwen2.5-VL-72B | 59.56 | 参考值 |

*注：以上为参考值，实际结果可能因评测环境而异*

---

## 📚 相关资源

- [Intelligence维度指南](../../../intelligence/README.md)

---

**最后更新**: 2025-11-30

