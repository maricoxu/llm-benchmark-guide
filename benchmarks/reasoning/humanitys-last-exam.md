# Humanity's Last Exam

> 综合问答评测集，面向"通用智能"能力的综合评测

## 📋 基本信息

| 项目 | 内容 |
|------|------|
| **分类** | Intelligence - 推理能力（综合问答） |
| **测试条目数** | 待定 |
| **输入长度** | 综合问题描述 |
| **输出长度** | 综合答案 |
| **评测时间** | 待定 |
| **覆盖场景** | 通用智能能力评估 |

---

## 📖 评测集介绍

Humanity's Last Exam是面向"通用智能"能力的综合评测集，用于评估模型在综合问答任务上的表现。

### 特点

- **综合能力**: 评估综合问答能力
- **通用智能**: 面向"通用智能"能力
- **综合评测**: 多维度综合评估
- **输入输出**: 输入为综合问题描述，输出为综合答案（通常200-1000 tokens）

### 适用场景

- 通用智能能力评估
- 综合问答能力评估
- 模型综合能力评估

### 适用模型

- **大模型（>10B）**: 强烈推荐，综合能力评估需要强大的模型能力
- **通用智能模型**: 特别推荐，如GPT-4、Claude-3等
- **中等模型（1B-10B）**: 可以使用，但可能表现有限

---

## 🔗 资源链接

- **GitHub**: 待定
- **论文**: 待定
- **数据集**: 待定

---

## 📖 使用指南

### 1. 数据准备

```python
# 待定具体的数据加载方法
```

### 2. 运行评测

#### 使用OpenCompass

```python
from opencompass import OpenCompass

config = {
    'dataset': 'humanitys_last_exam',
    'model': 'your_model',
    'temperature': 0
}

result = OpenCompass.run(config)
```

### 3. 结果分析

- **准确率**: 计算正确答案的比例
- **综合能力分析**: 分析模型在不同方面的表现
- **错误分析**: 分析错误类型和原因

---

## ⚙️ 评测参数

- **Temperature**: 待定
- **测试次数**: 待定
- **覆盖模型**: qwen3-235B-A22B-Thinking-2507等

---

## 📝 输入输出示例

### 示例1: 综合问答

**输入（Input）**:
```
问题: 待定具体示例
```

**期望输出（Expected Output）**:
```
待定具体示例
```

---

## 💡 最佳实践

1. **综合评估**: 从多个维度评估模型能力
2. **错误分析**: 深入分析错误案例

---

## 📊 参考结果

| 模型 | 准确率 | 备注 |
|------|--------|------|
| 待定 | 待定 | 参考值 |

*注：以上为参考值，实际结果可能因评测环境而异*

---

## 📚 相关资源

- [Intelligence维度指南](../../../intelligence/README.md)

---

**最后更新**: 2025-11-30

